{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS145 Howework 4, Naive Bayes\n",
    "\n",
    "<span style=\"color:red\"> **Due date:** </span>\n",
    "**11:59 PM PT, May 31 (Wednesday)**. Please submit on GradeScope.\n",
    "\n",
    "----\n",
    "\n",
    "## Print Out Your Name and UID\n",
    "\n",
    "<span style=\"color:blue\"> **Name: Joshua M, UID: 005154394** </span>\n",
    "\n",
    "## Before You Start\n",
    "\n",
    "You need to first create HW6 conda environment using `cs145hw4.yml` file.\n",
    "\n",
    "```\n",
    "conda env create -f cs145hw4.yml\n",
    "conda activate hw4\n",
    "conda deactivate\n",
    "```\n",
    "OR \n",
    "\n",
    "```\n",
    "conda env create --name NAMEOFYOURCHOICE -f cs145hw4.yml \n",
    "conda activate NAMEOFYOURCHOICE\n",
    "conda deactivate\n",
    "```\n",
    "To view the list of your environments, use the following command:\n",
    "```\n",
    "conda env list\n",
    "```\n",
    "\n",
    "In this notebook, you must not delete any code cells in this notebook. If you change any code outside the blocks (such as hyperparameters) that you are allowed to edit (between `STRART/END YOUR CODE HERE`), you need to highlight these changes. You may add some additional cells to help explain your results and observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8,8\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `seaborn` in HW6 is only used for ploting classification confusion matrix (in a \"heatmap\" style). If you encounter installation problem and cannot solve it, you can also use alternative libaries methods to show the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes for Text\n",
    "\n",
    "In the problem, you are given a document in `dataset` folder. The original data comes from [\"20 newsgroups\"](http://qwone.com/~jason/20Newsgroups/). You can use the provided data files to avoid repetitive preprocessing.\n",
    "\n",
    "Note: The code and dataset are under the subfolder named `nb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data processing and preparation\n",
    "# read train/test labels from files\n",
    "train_label = pd.read_csv('./nb/dataset/train.label',names=['t'])\n",
    "train_label = train_label['t'].tolist()\n",
    "test_label = pd.read_csv('./nb/dataset/test.label', names=['t'])\n",
    "test_label= test_label['t'].tolist()\n",
    "\n",
    "# read train/test documents from files\n",
    "train_data = open('./nb/dataset/train.data')\n",
    "df_train = pd.read_csv(train_data, delimiter=' ', names=['docIdx', 'wordIdx', 'count'])\n",
    "test_data = open('./nb/dataset/test.data')\n",
    "df_test = pd.read_csv(test_data, delimiter=' ', names=['docIdx', 'wordIdx', 'count'])\n",
    "\n",
    "# read vocab\n",
    "vocab = open('./nb/dataset/vocabulary.txt') \n",
    "vocab_df = pd.read_csv(vocab, names = ['word']) \n",
    "vocab_df = vocab_df.reset_index() \n",
    "vocab_df['index'] = vocab_df['index'].apply(lambda x: x+1) \n",
    "\n",
    "# add label column to original df_train\n",
    "docIdx = df_train['docIdx'].values\n",
    "i = 0\n",
    "new_label = []\n",
    "for index in range(len(docIdx)-1):\n",
    "    new_label.append(train_label[i])\n",
    "    if docIdx[index] != docIdx[index+1]:\n",
    "        i += 1\n",
    "new_label.append(train_label[i])\n",
    "df_train['classIdx'] = new_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have the data prepared properly, the following line of code would return the head of the `df_train` dataframe, which is,\n",
    "\n",
    "\n",
    "|  |  docIdx  |   wordIdx |  count  | classIdx |\n",
    "| :---: | :---:        |    :----:   |      :---: | :---: |\n",
    "| 0 | 1 | 1 | 4 | 1 |\n",
    "| 1\t| 1 | 2 | 2 | 1 |\n",
    "| 2 | 1 | 3 | 10 | 1 |\n",
    "| 3 | 1 | 4 | 4 | 1 |\n",
    "| 4 | 1 | 5 | 2 | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the head of 'df_train'\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the implementation of Naive Bayes model for text classification `nbm.py`.  After that,  run `nbm_sklearn.py`,  which uses `sklearn` to implement naive bayes model for text classification. (Note that the dataset is slightly different loaded in `nbm_sklearn.py` and also you don't need to change anything in `nbm_sklearn.py` and directly run it.) \n",
    "\n",
    "If your implementation is correct, you can expect around 0.9 training accuracy and >0.7 test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb.nbm import NB_model\n",
    "\n",
    "# model training\n",
    "nbm = NB_model()\n",
    "nbm.fit(df_train, train_label, vocab_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on train set to validate the model\n",
    "predict_train_labels = nbm.predict(df_train)\n",
    "train_acc = (np.array(train_label) == np.array(predict_train_labels)).mean()\n",
    "print(\"Accuracy on training data by my implementation: {}\".format(train_acc))\n",
    "\n",
    "# make predictions on test data\n",
    "predict_test_labels = nbm.predict(df_test)\n",
    "test_acc = (np.array(test_label) == np.array(predict_test_labels)).mean()\n",
    "print(\"Accuracy on testing data by my implementation: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot classification matrix\n",
    "mat = confusion_matrix(test_label, predict_test_labels)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.title('Classification Performace by sklearn')\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./nb/output/nbm_mine.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **Reminder:** </span> Do not forget to run nbm_sklearn.py to compare the results to get the accuracy and confusion matrix by sklearn implementation. You can run `python nbm_sklearn.py` under the folder path of `./hw6/nb/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question & Analysis**\n",
    "\n",
    "1. Report your classification accuracy on train and test documents. Also report your classification confusion matrix. Show one example document that Naive Bayes classifies incorrectly (i.e. fill in the following result table). Briefly explain your observation on the accuracy and confusion matrix.\n",
    "\n",
    "|    |   Train set accuracy |  Test set accuracy  |\n",
    "| :---        |    :----:   |                ---: |\n",
    "| sklearn implementaion|          |               |\n",
    "| your implementaion   |          |               |\n",
    "\n",
    "2. Show one example document that Naive Bayes classifies incorrectly by filling the following table. Provide your thought on the reason why this document is misclassified. (Note that the topic mapping is available at `train.map` same as `test.map`)\n",
    "\n",
    "|  Words (count) in the example document  | Predicted label |  Truth label |\n",
    "| :---        |    :----:   |                ---: |\n",
    "| For example, student (4), education (2), ... |     Class A     |   Class B    |\n",
    "\n",
    "3. Is Naive Bayes a generative model or discriminative model and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
