{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS145 Howework 3, Part 1: kNN\n",
    "\n",
    "<span style=\"color:red\"> **Important Note:** </span>\n",
    "HW3 is due on **11:59 PM PT, May 15 (Monday)**. Please submit through GradeScope.\n",
    "\n",
    "Note that Howework #3 includes two jupyter notebooks (Part 1: kNN and Part 2: Neural Network), please merge the reports into one pdf in your submission.\n",
    "\n",
    "----\n",
    "\n",
    "## Print Out Your Name and UID\n",
    "\n",
    "<span style=\"color:blue\"> **Name: Joshua Mares, UID: 005154394** </span>\n",
    "\n",
    "----\n",
    "\n",
    "## Before You Start\n",
    "\n",
    "You need to first create HW3 conda environment specified in `cs145hw3.yml` file. If you have `conda` properly installed, you may create, activate or deactivate the env with the following commands:\n",
    "\n",
    "```\n",
    "conda env create -f cs145hw3.yml\n",
    "conda activate hw3\n",
    "conda deactivate\n",
    "```\n",
    "OR\n",
    "\n",
    "```\n",
    "conda env create --name NAMEOFYOURCHOICE -f cs145hw3.yml \n",
    "conda activate NAMEOFYOURCHOICE\n",
    "conda deactivate\n",
    "```\n",
    "To view the list of your environments, use the following command:\n",
    "```\n",
    "conda env list\n",
    "```\n",
    "\n",
    "References can be found [here](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html).\n",
    "\n",
    "You must not delete any code cells in this notebook. If you change any code outside the blocks (such as hyperparameters) that you are allowed to edit (between `STRART/END YOUR CODE HERE`), you need to highlight these changes. You may add some additional cells to help explain your results and observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and prepare the dataset\n",
    "\n",
    "Download the CIFAR-10 dataset (file size: ~163M) [here](http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz). Unzip and place the folder under `hw3/data/datasets/`.\n",
    "\n",
    "After downloading the dataset, you can start your notebook from the HW3 directory. Note that the dataset is used in both jupyter notebooks (kNN and Neural Networks). You only need to download the dataset once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the appropriate libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # for doing most of our calculations\n",
    "import matplotlib.pyplot as plt# for plotting\n",
    "from data.data_utils import load_CIFAR10 # function to load the CIFAR-10 dataset.\n",
    "\n",
    "# Load matplotlib images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# These are important for reloading any code you write in external .py files.\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to verify that the dataset has been successfully installed, use the following code to print out the shape of train/test data and labels. The output shapes for train/test data should be (50000, 32, 32, 3) and (10000, 32, 32, 3), and the label size should be (50000,) and (10000,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_CIFAR10' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Set the path to the CIFAR-10 data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m cifar10_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/datasets/cifar-10-batches-py\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mload_CIFAR10\u001b[49m(cifar10_dir)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# As a sanity check, we print out the size of the training and test data.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining data shape: \u001b[39m\u001b[38;5;124m'\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_CIFAR10' is not defined"
     ]
    }
   ],
   "source": [
    "# Set the path to the CIFAR-10 data\n",
    "cifar10_dir = './data/datasets/cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize some examples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample the data to speedup the experiments\n",
    "num_training = 5000\n",
    "mask = list(range(num_training))\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "num_test = 500\n",
    "mask = list(range(num_test))\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "# Reshape the image data into rows\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement K-nearest neighbors algorithms\n",
    "\n",
    "In the following cells, you will build a KNN classifier and choose hyperparameters via k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the KNN class\n",
    "from hw3code import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare an instance of the knn class.\n",
    "knn = KNN()\n",
    "\n",
    "# Train the classifier.\n",
    "#   We have implemented the training of the KNN classifier.\n",
    "#   Look at the train function in the KNN class to see what this does.\n",
    "knn.train(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "(1) Describe what is going on in the function knn.train().\n",
    "\n",
    "(2) What are the pros and cons of this training step of KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers**\n",
    "\n",
    "<span style=\"color:blue\"> Please write down your answer here! </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN prediction\n",
    "\n",
    "In the following sections, you will implement the functions to calculate the distances of test points to training points, and from this information, predict the class of the KNN. \\\n",
    "**Hint: If you implemented this correctly, evaluating np.linalg.norm(dists_L2, 'fro') should return: ~7906696**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the function compute_distances() in the KNN class.\n",
    "# Do not worry about the input 'norm' for now; use the default definition of the norm\n",
    "#   in the code, which is the 2-norm.\n",
    "# You should only have to fill out the clearly marked sections.\n",
    "\n",
    "import time\n",
    "time_start =time.time()\n",
    "\n",
    "dists_L2 = knn.compute_distances(X=X_test)\n",
    "\n",
    "print('Time to run code: {}'.format(time.time()-time_start))\n",
    "print('Frobenius norm of L2 distances: {}'.format(np.linalg.norm(dists_L2, 'fro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Really slow?\n",
    "\n",
    "The above code probably takes a while to finish. This is because we are using iterative implementation (two for loops).  We could optimize the implementation with vectorization, i.e. by removing the for loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN vectorization\n",
    "\n",
    "The above code took far too long to run.  If we wanted to optimize hyperparameters, it would be time-expensive.  Thus, we will speed up the code by vectorizing it, removing the for loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the function compute_L2_distances_vectorized() in the KNN class.\n",
    "# In this function, you ought to achieve the same L2 distance but WITHOUT any for loops.\n",
    "# Note, this is SPECIFIC for the L2 norm.\n",
    "\n",
    "time_start =time.time()\n",
    "dists_L2_vectorized = knn.compute_L2_distances_vectorized(X=X_test)\n",
    "print('Time to run code: {}'.format(time.time()-time_start))\n",
    "print('Difference in L2 distances between your KNN implementations (should be 0): {}'.format(np.linalg.norm(dists_L2 - dists_L2_vectorized, 'fro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speedup\n",
    "\n",
    "You should see a 20-100x speed up from vectorization and no difference in L2 distances between two implementations. \n",
    "\n",
    "On our computer, the vectorized form took 0.20 seconds while the naive implementation took 26.88 seconds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing KNN prediction\n",
    "\n",
    "Now that we have functions to calculate the distances from a test point to given training points, we can implement the function that predicts the test point labels. If you implemented this correctly, the error should be around 0.71. This means that the k-nearest neighbors classifier is right only around 29% of the time, which is not great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the function predict_labels in the KNN class.\n",
    "# Calculate the training error (num_incorrect / total_samples) \n",
    "#   from running knn.predict_labels with k=10\n",
    "\n",
    "error = 1\n",
    "\n",
    "# ================================================================ #\n",
    "# START YOUR CODE HERE\n",
    "# ================================================================ #\n",
    "#   Calculate the error rate by calling predict_labels on the test \n",
    "#   data with k = 10.  Store the error rate in the variable error.\n",
    "# ================================================================ #\n",
    "\n",
    "# ================================================================ #\n",
    "# END YOUR CODE HERE\n",
    "# ================================================================ #\n",
    "\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Homework 3, Part 1\n",
    "\n",
    "After you've finished both parts the homework, please print out the both of the entire `ipynb` notebooks and `py` files into one PDF file. Make sure you include the output of code cells and answers for questions. Prepare submit it to GradeScope. Do not include any dataset in your submission.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
